{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41e917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2f0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make_vec('LunarLander-v3', num_envs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfdeb12",
   "metadata": {},
   "source": [
    "Checking out environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001819ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
       "   -0.         -0.       ]\n",
       " [ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
       "   -0.         -0.       ]\n",
       " [ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
       "   -0.         -0.       ]\n",
       " [ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
       "   -0.         -0.       ]], [[ 2.5        2.5       10.        10.         6.2831855 10.\n",
       "   1.         1.       ]\n",
       " [ 2.5        2.5       10.        10.         6.2831855 10.\n",
       "   1.         1.       ]\n",
       " [ 2.5        2.5       10.        10.         6.2831855 10.\n",
       "   1.         1.       ]\n",
       " [ 2.5        2.5       10.        10.         6.2831855 10.\n",
       "   1.         1.       ]], (4, 8), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df50755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03253634, -0.88300264, -7.865607  , -5.336766  ,  0.434043  ,\n",
       "        -7.9357414 ,  0.9586344 ,  0.5768451 ],\n",
       "       [ 1.093525  , -1.5775923 , -7.3541307 , -9.811705  ,  3.937337  ,\n",
       "        -3.7853758 ,  0.27572083,  0.804381  ],\n",
       "       [-0.7951227 ,  1.5547985 ,  2.4960365 ,  3.3656154 , -5.766545  ,\n",
       "        -0.26347592,  0.30940792,  0.22402176],\n",
       "       [ 0.05055139, -0.45805088, -3.811204  ,  8.166333  , -3.594789  ,\n",
       "        -4.828926  ,  0.23119257,  0.9492218 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_sample = env.observation_space.sample()\n",
    "obs_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61edaaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ddf54af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiDiscrete([4 4 4 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816f1d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_sample = env.action_space.sample()\n",
    "actions_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595fe447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00305958,  1.4203336 ,  0.30988377,  0.41837493, -0.00353846,\n",
       "        -0.07019331,  0.        ,  0.        ],\n",
       "       [-0.00247841,  1.3984988 , -0.2510584 , -0.5520632 ,  0.00287873,\n",
       "         0.05686847,  0.        ,  0.        ],\n",
       "       [ 0.00156975,  1.4137702 ,  0.15898359,  0.12667738, -0.00181216,\n",
       "        -0.03601218,  0.        ,  0.        ],\n",
       "       [-0.00418701,  1.4193463 , -0.42412192,  0.37449604,  0.00485856,\n",
       "         0.09607007,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states, info = env.reset()\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af40433",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_states, rewards, dones, terminated, _ = env.step(actions_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0b37c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.1192513e-03,  1.4291688e+00,  3.0946472e-01,  3.9266151e-01,\n",
       "        -7.0069069e-03, -6.9374286e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-5.0230981e-03,  1.3866826e+00, -2.5699800e-01, -5.2516639e-01,\n",
       "         5.3823702e-03,  5.0078470e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 3.0511855e-03,  1.4160452e+00,  1.4769444e-01,  1.0111109e-01,\n",
       "        -1.3705736e-03,  8.8333674e-03,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-8.4383013e-03,  1.4272060e+00, -4.3155876e-01,  3.4928420e-01,\n",
       "         1.1211531e-02,  1.2707140e-01,  0.0000000e+00,  0.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7b0951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83746879,  2.80967754,  2.21555632, -0.39298463])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad3a52fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones # done is when state successfully finished or passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435cfc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminated # terminated is when agent failed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a368cfc",
   "metadata": {},
   "source": [
    "Setting up networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94831b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch.optim as opt\n",
    "import random\n",
    "from torch.distributions.categorical import Categorical\n",
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53425ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, hidden_size: int):\n",
    "        super(Actor, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, out_features),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, states: torch.tensor) -> torch.tensor:\n",
    "        dist = self.layers(states)\n",
    "        return Categorical(dist)\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self,  in_features: int, out_features: int, hidden_size: int):\n",
    "        super(Critic, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, states: torch.tensor) -> torch.tensor:\n",
    "        return self.layers(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, env, actor: Actor, critic: Critic, epsilon: float, gamma: float, lam: float, actor_lr: float, critic_lr: float):\n",
    "        self.env = env\n",
    "        self.actor = actor\n",
    "        self.critic = critic\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.actor_lr = actor_lr\n",
    "        self.critic_lr = critic_lr\n",
    "        self.actor_opt = opt.Adam(self.actor.parameters(), actor_lr)\n",
    "        self.critic_opt = opt.Adam(self.critic.parameters(), critic_lr)\n",
    "\n",
    "    def save_agent(self, path: str = 'cartpole_agent.pt') -> None:\n",
    "        torch.save({\n",
    "            'actor': self.actor.state_dict(),\n",
    "            'critic': self.critic.state_dict(),\n",
    "            'hyperparameters': {\n",
    "                'actor_lr': self.actor_lr,\n",
    "                'critic_lr': self.critic_lr,\n",
    "                'epsilon': self.epsilon,\n",
    "                'gamma': self.gamma,\n",
    "                'lam': self.lam,\n",
    "                'actor_in_feats': self.actor.in_features,\n",
    "                'actor_out_feats': self.actor.out_features,\n",
    "                'critic_in_feats': self.critic.in_features,\n",
    "                'critic_out_feats': self.critic.out_features,\n",
    "                'actor_hidden_size': self.actor.hidden_size,\n",
    "                'critic_hidden_size': self.critic.hidden_size,\n",
    "            }\n",
    "        }, path)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_agent(env, path: str, device: str) -> 'Agent':\n",
    "        chckpt = torch.load(path)\n",
    "\n",
    "        actor = Actor(chckpt['hyperparameters']['actor_in_feats'], chckpt['hyperparameters']['actor_out_feats'], chckpt['hyperparameters']['actor_hidden_size']).to(device)\n",
    "        critic = Critic(chckpt['hyperparameters']['critic_in_feats'], chckpt['hyperparameters']['critic_out_feats'], chckpt['hyperparameters']['critic_hidden_size']).to(device)\n",
    "        actor.load_state_dict(chckpt['actor'])\n",
    "        critic.load_state_dict(chckpt['critic'])\n",
    "\n",
    "        return Agent(\n",
    "            env, \n",
    "            actor, \n",
    "            critic, \n",
    "            chckpt['hyperparameters']['epsilon'],\n",
    "            chckpt['hyperparameters']['gamma'],\n",
    "            chckpt['hyperparameters']['lam'],\n",
    "            chckpt['hyperparameters']['actor_lr'],\n",
    "            chckpt['hyperparameters']['critic_lr']\n",
    "        )\n",
    "\n",
    "\n",
    "    def select_action(self, states: torch.tensor) -> tuple:\n",
    "        dist = self.actor.forward(states)\n",
    "        actions = dist.sample()\n",
    "\n",
    "        return actions, dist.log_prob(actions)  \n",
    "    \n",
    "    def get_state_values(self, states: torch.tensor) -> torch.tensor:\n",
    "        return self.critic.forward(states)\n",
    "\n",
    "    def update_nets(self, actor_loss: torch.tensor, critic_loss: torch.tensor) -> None:\n",
    "        self.actor_opt.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_opt.step()\n",
    "\n",
    "        self.critic_opt.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_opt.step()\n",
    "\n",
    "    def fit(self, train_iters: int, timesteps: int, K: int, bs: int) -> None:\n",
    "        if bs > self.env.num_envs * timesteps:\n",
    "            raise ValueError('batch size cannot be greater than number of environments * timesteps')\n",
    "        \n",
    "        self.all_rewards = []\n",
    "        self.all_steps = []\n",
    "\n",
    "        for train_iter in range(train_iters):\n",
    "            rollout = []\n",
    "            ep_reward = 0\n",
    "            ep_steps = 0\n",
    "\n",
    "            states, _ = self.env.reset()\n",
    "            states = torch.from_numpy(states).to(device)\n",
    "\n",
    "            for _ in range(timesteps):\n",
    "                actions, probs = self.select_action(states)\n",
    "                state_vals = self.get_state_values(states)\n",
    "\n",
    "                next_states, rewards, dones, terminated, _ = self.env.step(actions.detach().cpu().numpy())\n",
    "                next_states = torch.from_numpy(next_states).to(device)\n",
    "                rewards = torch.from_numpy(rewards)\n",
    "                dones = torch.from_numpy(dones)\n",
    "\n",
    "                ep_reward += sum(rewards).item()\n",
    "\n",
    "                next_state_vals = self.get_state_values(next_states)\n",
    "                for s, sv, ns, nsv, a, p, r, d in zip(states, state_vals.detach(), next_states, next_state_vals, actions, probs.detach(), rewards, dones):\n",
    "                    rollout.append([s, sv, ns, nsv, a, p, r, d])\n",
    "\n",
    "                states = next_states\n",
    "                ep_steps += 1\n",
    "            \n",
    "            print('finished episode:', train_iter)\n",
    "            print('total reward:', ep_reward)\n",
    "            print('number of steps:', ep_steps)\n",
    "            print('-' * 15)\n",
    "\n",
    "            self.all_rewards.append(ep_reward)\n",
    "            self.all_steps.append(ep_steps)\n",
    "\n",
    "            # next_advantage = 0\n",
    "            # for t in reversed(range(len(rollout))):\n",
    "            #     delta = rollout[t][6] + self.gamma * (rollout[t][3] if t + 1 < len(rollout) else 0) - rollout[t][1]\n",
    "            #     rollout[t].append((delta + self.gamma * self.lam * next_advantage).detach())\n",
    "            #     next_advantage = rollout[t][8]\n",
    "\n",
    "            for i in range(len(advantages) - 1): # dont go out of bounds\n",
    "                discount = 1\n",
    "                advantage_t = 0\n",
    "                for j in range(i, len(rollout) - 1):\n",
    "                    delta = (rollout[j][6] + self.gamma * rollout[j][3] - rollout[j][1])\n",
    "                    advantage_t += discount * delta\n",
    "                rollout[i].append(advantage_t)\n",
    "                discount *= self.gamma * self.lam\n",
    "\n",
    "            for _ in range(K):\n",
    "                samples = random.sample(rollout, bs)\n",
    "                states = torch.stack([s[0] for s in samples])\n",
    "                old_probs = torch.stack([s[5] for s in samples]) # get action probabilites from samples\n",
    "                actions = torch.stack([s[4] for s in samples]) # get selected actions from samples\n",
    "\n",
    "                advantages = torch.tensor([s[8] for s in samples]).to(device)\n",
    "                advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "                new_probs = torch.stack([self.actor.forward(state).log_prob(action) for state, action in zip(states, actions)]) # get new action probs from sample states\n",
    "                ratio = (new_probs - old_probs).exp()\n",
    "\n",
    "                returns = advantages + torch.stack([s[1] for s in samples])\n",
    "\n",
    "                critic_loss = ((returns - self.critic.forward(states)) ** 2).mean() # loss for critic network\n",
    "                actor_loss = -torch.min(ratio * advantages, torch.clamp(ratio, 1 - self.epsilon, 1 + self.epsilon) * advantages).mean()\n",
    "                self.update_nets(actor_loss, critic_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32502f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(8, 4, 64).to(device)\n",
    "critic = Critic(8, 1, 64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64e34abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical(logits: torch.Size([4, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_sample = torch.from_numpy(obs_sample).to(device)\n",
    "dist = actor.forward(obs_sample)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c4f1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54263ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4147, -1.5126, -1.3745, -1.6495], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deff9ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2430, 0.2203, 0.2530, 0.1921], device='cuda:0',\n",
       "       grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(test_sample).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b29b938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6404],\n",
       "        [-0.5591],\n",
       "        [-0.4051],\n",
       "        [-0.8154]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic.forward(obs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3704ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(env, actor, critic, 0.2, 0.999, 0.98, 0.001, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d86ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished episode: 0\n",
      "total reward: -1026.7723753378766\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 1\n",
      "total reward: -562.0362175447955\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 2\n",
      "total reward: -352.25816712982686\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 3\n",
      "total reward: -707.0751132690879\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 4\n",
      "total reward: -589.6928397841383\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 5\n",
      "total reward: -628.1823560398917\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 6\n",
      "total reward: -1020.8369415126723\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 7\n",
      "total reward: -1011.7752862939551\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 8\n",
      "total reward: -1044.5596212039877\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 9\n",
      "total reward: -1126.720282172506\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 10\n",
      "total reward: -253.9549851197329\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 11\n",
      "total reward: -853.3546303421925\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 12\n",
      "total reward: -747.4381137827723\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 13\n",
      "total reward: -1331.261117567868\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 14\n",
      "total reward: -782.0393475949194\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 15\n",
      "total reward: -1020.5997395437514\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 16\n",
      "total reward: -1110.6627293437266\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 17\n",
      "total reward: -846.7174976617416\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 18\n",
      "total reward: -1218.731868118752\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 19\n",
      "total reward: -1066.1738482492703\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 20\n",
      "total reward: -793.919978288358\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 21\n",
      "total reward: -361.09086561041545\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 22\n",
      "total reward: -1122.1405501032043\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 23\n",
      "total reward: -1130.0990185268952\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 24\n",
      "total reward: -1070.4003295380442\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 25\n",
      "total reward: -450.81485299606516\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 26\n",
      "total reward: -895.5919624387683\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 27\n",
      "total reward: -261.57264391401725\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 28\n",
      "total reward: -679.9325110500132\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 29\n",
      "total reward: -908.8836619915652\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 30\n",
      "total reward: -730.8719065708631\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 31\n",
      "total reward: -557.404936925363\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 32\n",
      "total reward: -445.34120011971726\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 33\n",
      "total reward: -611.7576677139563\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 34\n",
      "total reward: -814.7457114822379\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 35\n",
      "total reward: -802.5171842008709\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 36\n",
      "total reward: -675.4505995675556\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 37\n",
      "total reward: -1055.8544083742959\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 38\n",
      "total reward: -636.1978011815215\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 39\n",
      "total reward: -609.1676902746299\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 40\n",
      "total reward: -605.6827843569777\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 41\n",
      "total reward: -625.1937772499119\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 42\n",
      "total reward: -1056.8492647682217\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 43\n",
      "total reward: -424.59957814417044\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 44\n",
      "total reward: -452.7585702882303\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 45\n",
      "total reward: -236.25537586517436\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 46\n",
      "total reward: -771.8697031588661\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 47\n",
      "total reward: -798.5216854682003\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 48\n",
      "total reward: -894.957813041641\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 49\n",
      "total reward: -313.88004403253717\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 50\n",
      "total reward: -643.1140976529856\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 51\n",
      "total reward: -327.24364216940506\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 52\n",
      "total reward: -831.0368897838417\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 53\n",
      "total reward: -894.4375988819177\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 54\n",
      "total reward: -455.5396713315089\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 55\n",
      "total reward: -864.6426840452077\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 56\n",
      "total reward: -889.9718972183574\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 57\n",
      "total reward: -727.5518275607266\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 58\n",
      "total reward: -992.0239209245585\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 59\n",
      "total reward: -412.7830804002025\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 60\n",
      "total reward: -486.1398302664042\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 61\n",
      "total reward: -689.2308149089691\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 62\n",
      "total reward: -930.10736977714\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 63\n",
      "total reward: -1005.8381577071854\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 64\n",
      "total reward: -1173.4692405395551\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 65\n",
      "total reward: -994.7777736836036\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 66\n",
      "total reward: -940.4447863549916\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 67\n",
      "total reward: -939.4619763746665\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 68\n",
      "total reward: -1138.0344817722046\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 69\n",
      "total reward: -895.0295687546269\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 70\n",
      "total reward: -1096.9802354536828\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 71\n",
      "total reward: -674.1384162491092\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 72\n",
      "total reward: -203.3714693878998\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 73\n",
      "total reward: -534.3903957308\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 74\n",
      "total reward: -593.4076431153353\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 75\n",
      "total reward: -391.4028812383155\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 76\n",
      "total reward: -873.6036854435565\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 77\n",
      "total reward: -508.35896575665055\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 78\n",
      "total reward: -142.26353209474667\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 79\n",
      "total reward: -1083.9709150755714\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 80\n",
      "total reward: -622.79956522106\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 81\n",
      "total reward: -674.0614193146056\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 82\n",
      "total reward: -602.8661077363607\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 83\n",
      "total reward: -658.5474153996862\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 84\n",
      "total reward: -1062.5364585312202\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 85\n",
      "total reward: -486.86717286683927\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 86\n",
      "total reward: -153.9026995734514\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 87\n",
      "total reward: -432.2139559769508\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 88\n",
      "total reward: -646.3037208159071\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 89\n",
      "total reward: -442.0466656893782\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 90\n",
      "total reward: -82.26632939076556\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 91\n",
      "total reward: -396.5325324022439\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 92\n",
      "total reward: -424.5747438635131\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 93\n",
      "total reward: -210.57969009170702\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 94\n",
      "total reward: -507.1286601226276\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 95\n",
      "total reward: -847.5956362673179\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 96\n",
      "total reward: -189.0713354166771\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 97\n",
      "total reward: -669.7842339766996\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 98\n",
      "total reward: -801.2538151204503\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 99\n",
      "total reward: -513.8310581952229\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 100\n",
      "total reward: -612.8866837093454\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 101\n",
      "total reward: -464.5329063770088\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 102\n",
      "total reward: -459.5146365251656\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 103\n",
      "total reward: -376.6529434265156\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 104\n",
      "total reward: -384.0384739324032\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 105\n",
      "total reward: -351.3028100879376\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 106\n",
      "total reward: -133.44633102291428\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 107\n",
      "total reward: -150.99997088711635\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 108\n",
      "total reward: -327.4614169013766\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 109\n",
      "total reward: -310.05025664025993\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 110\n",
      "total reward: -422.3056922465681\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 111\n",
      "total reward: -82.55348660231341\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 112\n",
      "total reward: -126.00627101566761\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 113\n",
      "total reward: -39.426833150673154\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 114\n",
      "total reward: -445.56971118729683\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 115\n",
      "total reward: -232.0303989175902\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 116\n",
      "total reward: -346.4415931448747\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 117\n",
      "total reward: -267.8239845822258\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 118\n",
      "total reward: -43.29186332376979\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 119\n",
      "total reward: -135.27473081572762\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 120\n",
      "total reward: -224.76444474042484\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 121\n",
      "total reward: -413.41696843697554\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 122\n",
      "total reward: -420.5824598807647\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 123\n",
      "total reward: -822.1578785442405\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 124\n",
      "total reward: -531.7112527681105\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 125\n",
      "total reward: -478.94614379346086\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 126\n",
      "total reward: -146.42708010886474\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 127\n",
      "total reward: -493.5452239817297\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 128\n",
      "total reward: -492.7757606714127\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 129\n",
      "total reward: -650.195679375858\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 130\n",
      "total reward: -571.3814438639849\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 131\n",
      "total reward: -748.2256356551959\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 132\n",
      "total reward: -268.8249800855182\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 133\n",
      "total reward: -43.99051042085598\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 134\n",
      "total reward: -73.66357759714799\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 135\n",
      "total reward: -57.40441638925287\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 136\n",
      "total reward: -243.46842071104078\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 137\n",
      "total reward: -78.68611239406616\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 138\n",
      "total reward: -376.2834053058686\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 139\n",
      "total reward: 0.6594507444647684\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 140\n",
      "total reward: -102.69981089760202\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 141\n",
      "total reward: 165.3672067253072\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 142\n",
      "total reward: 34.74934610811606\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 143\n",
      "total reward: -75.18975340457445\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 144\n",
      "total reward: 11.81590106877525\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 145\n",
      "total reward: 123.32193801271295\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 146\n",
      "total reward: 15.784016595102521\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 147\n",
      "total reward: -4.652106506048202\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 148\n",
      "total reward: 2.2499230621667543\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 149\n",
      "total reward: 48.71901756673893\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 150\n",
      "total reward: 47.52411699642671\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 151\n",
      "total reward: -53.31252169604072\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 152\n",
      "total reward: -81.35791438654034\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 153\n",
      "total reward: -195.3412570881643\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 154\n",
      "total reward: -285.9846061494634\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 155\n",
      "total reward: -331.0525969050901\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 156\n",
      "total reward: -80.8670625513696\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 157\n",
      "total reward: 10.143550468671904\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 158\n",
      "total reward: 2.8062152386718573\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 159\n",
      "total reward: 54.087457408005484\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 160\n",
      "total reward: 117.0074474416718\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 161\n",
      "total reward: -5.0144500903340345\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 162\n",
      "total reward: -4.827306374958268\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 163\n",
      "total reward: -90.53328390392652\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 164\n",
      "total reward: -511.04078400305747\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 165\n",
      "total reward: -70.28520972416891\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 166\n",
      "total reward: -54.73009884683828\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 167\n",
      "total reward: 9.473308891829085\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 168\n",
      "total reward: -19.675401773825456\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 169\n",
      "total reward: -48.16417194838053\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 170\n",
      "total reward: 95.51169432356187\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 171\n",
      "total reward: 87.46294199044151\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 172\n",
      "total reward: 40.8928739576146\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 173\n",
      "total reward: 50.163419048958026\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 174\n",
      "total reward: 131.9362396212593\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 175\n",
      "total reward: 14.55445313751132\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 176\n",
      "total reward: -29.265427151173302\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 177\n",
      "total reward: 20.538649023269745\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 178\n",
      "total reward: -43.55863553797837\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 179\n",
      "total reward: -134.76647280881173\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 180\n",
      "total reward: -116.64235060180903\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 181\n",
      "total reward: -126.92938526568255\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 182\n",
      "total reward: -90.68042341044122\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 183\n",
      "total reward: -71.44430915052632\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 184\n",
      "total reward: 21.36265576365328\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 185\n",
      "total reward: -57.03893376193621\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 186\n",
      "total reward: -4.728824186922129\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 187\n",
      "total reward: -123.42324069249236\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 188\n",
      "total reward: 50.899736405889605\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 189\n",
      "total reward: -58.95160712102821\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 190\n",
      "total reward: -51.25034652817503\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 191\n",
      "total reward: -37.959301653206694\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 192\n",
      "total reward: -90.06822107367253\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 193\n",
      "total reward: 16.20644909608136\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 194\n",
      "total reward: 82.13759226957127\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 195\n",
      "total reward: 57.35893449501449\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 196\n",
      "total reward: 4.732209730665659\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 197\n",
      "total reward: 17.493891368110372\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 198\n",
      "total reward: 122.34088118210128\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 199\n",
      "total reward: -25.153691787274443\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 200\n",
      "total reward: 15.035017878820756\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 201\n",
      "total reward: 57.006452030332355\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 202\n",
      "total reward: -0.6219899014066177\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 203\n",
      "total reward: 17.597621899906052\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 204\n",
      "total reward: 98.8925924824254\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 205\n",
      "total reward: 40.37141506716581\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 206\n",
      "total reward: 67.79230430538509\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 207\n",
      "total reward: -9.847872947120862\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 208\n",
      "total reward: 49.094224433875574\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 209\n",
      "total reward: 80.44789782284235\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 210\n",
      "total reward: -39.073299673881856\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 211\n",
      "total reward: 11.097579012033332\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 212\n",
      "total reward: 35.18417855111091\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 213\n",
      "total reward: 71.50355197684206\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 214\n",
      "total reward: 46.20859359008224\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 215\n",
      "total reward: 102.11492042622125\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 216\n",
      "total reward: 87.35195712242103\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 217\n",
      "total reward: 182.58646845347852\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 218\n",
      "total reward: 125.83480900210816\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 219\n",
      "total reward: 165.67970014836263\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 220\n",
      "total reward: 172.19186454415296\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 221\n",
      "total reward: 65.90682298977868\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 222\n",
      "total reward: -37.32752361138175\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 223\n",
      "total reward: -85.97137899573111\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 224\n",
      "total reward: -28.247895503611048\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 225\n",
      "total reward: 59.080471424491044\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 226\n",
      "total reward: 2.2375229250854787\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 227\n",
      "total reward: 117.62048840213836\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 228\n",
      "total reward: 70.06088451269548\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 229\n",
      "total reward: -5.807015194086923\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 230\n",
      "total reward: 97.68925121313453\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 231\n",
      "total reward: 90.38779831854065\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 232\n",
      "total reward: 51.674191696392\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 233\n",
      "total reward: 27.786177816814774\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 234\n",
      "total reward: 60.9518339716916\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 235\n",
      "total reward: 41.971127556247396\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 236\n",
      "total reward: 49.40822543394009\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 237\n",
      "total reward: -2.2350232930189264\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 238\n",
      "total reward: 94.83949915110674\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 239\n",
      "total reward: 36.519515177869934\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 240\n",
      "total reward: 78.82704488541893\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 241\n",
      "total reward: 116.6101050202734\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 242\n",
      "total reward: 93.19780016921197\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 243\n",
      "total reward: 150.4731120030246\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 244\n",
      "total reward: 142.02571091078525\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 245\n",
      "total reward: 179.4062733429418\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 246\n",
      "total reward: 85.03199389334065\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 247\n",
      "total reward: 165.9513581525731\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 248\n",
      "total reward: 129.12342054661113\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 249\n",
      "total reward: 123.11108329028237\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 250\n",
      "total reward: 86.52171125970743\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 251\n",
      "total reward: 108.85400805414224\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 252\n",
      "total reward: -27.733715582743823\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 253\n",
      "total reward: -75.68262480897971\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 254\n",
      "total reward: -83.7590275289079\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 255\n",
      "total reward: -13.058150311993113\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 256\n",
      "total reward: 51.29892533930544\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 257\n",
      "total reward: 91.73044301191008\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 258\n",
      "total reward: 44.435247576724606\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 259\n",
      "total reward: 58.02029199919517\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 260\n",
      "total reward: 76.13101141504936\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 261\n",
      "total reward: 59.28991741721202\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 262\n",
      "total reward: 48.05225409492799\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 263\n",
      "total reward: 140.90534039138123\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 264\n",
      "total reward: 101.44670381112982\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 265\n",
      "total reward: 132.43627314421872\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 266\n",
      "total reward: 113.45473446323857\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 267\n",
      "total reward: 104.35563523831493\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 268\n",
      "total reward: 120.91465242385603\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 269\n",
      "total reward: 162.19084486234811\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 270\n",
      "total reward: 57.62402515394437\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 271\n",
      "total reward: 82.26621162901424\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 272\n",
      "total reward: 67.14124021183525\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 273\n",
      "total reward: 67.99412809356186\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 274\n",
      "total reward: -37.57580458769106\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 275\n",
      "total reward: 33.1775120340441\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 276\n",
      "total reward: 14.420741208081719\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 277\n",
      "total reward: -19.2971818484054\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 278\n",
      "total reward: 121.72042759156557\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 279\n",
      "total reward: 7.157041501071976\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 280\n",
      "total reward: 109.36972719287157\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 281\n",
      "total reward: 118.08499017466882\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 282\n",
      "total reward: 56.56375936752174\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 283\n",
      "total reward: 141.90611060112488\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 284\n",
      "total reward: 27.43030814859684\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 285\n",
      "total reward: 154.31558206140463\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 286\n",
      "total reward: 47.60361058500777\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 287\n",
      "total reward: 67.17593870418864\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 288\n",
      "total reward: 137.2716661585737\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 289\n",
      "total reward: 162.20843045370918\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 290\n",
      "total reward: 159.96981434994453\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 291\n",
      "total reward: 172.6999254069555\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 292\n",
      "total reward: 67.77445727172781\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 293\n",
      "total reward: 32.42998608200663\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 294\n",
      "total reward: 43.87120183829051\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 295\n",
      "total reward: 63.960470049719355\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 296\n",
      "total reward: 8.144119759786669\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 297\n",
      "total reward: 19.684976474284433\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 298\n",
      "total reward: 81.44754813880922\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 299\n",
      "total reward: -30.41664260730753\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 300\n",
      "total reward: -23.56329531052453\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 301\n",
      "total reward: 146.29769906834727\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 302\n",
      "total reward: 113.24812962648393\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 303\n",
      "total reward: -23.303143305589384\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 304\n",
      "total reward: 115.08129155045289\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 305\n",
      "total reward: 56.25960508560336\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 306\n",
      "total reward: 75.53839509626526\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 307\n",
      "total reward: 26.400853938877415\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 308\n",
      "total reward: 73.4174830411531\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 309\n",
      "total reward: 66.23619745979128\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 310\n",
      "total reward: 108.27684912878036\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 311\n",
      "total reward: 166.18321317781297\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 312\n",
      "total reward: 152.90497082591187\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 313\n",
      "total reward: 156.5932898650827\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 314\n",
      "total reward: 61.479273094315204\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 315\n",
      "total reward: 47.511300871534075\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 316\n",
      "total reward: 82.88587623848086\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 317\n",
      "total reward: 44.96748182307563\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 318\n",
      "total reward: -5.610841880212543\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 319\n",
      "total reward: -25.442152244389575\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 320\n",
      "total reward: -69.2042741012637\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 321\n",
      "total reward: 11.416531926554757\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 322\n",
      "total reward: 4.152839243454016\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 323\n",
      "total reward: -100.79174620487976\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 324\n",
      "total reward: 105.0200234447068\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 325\n",
      "total reward: 68.05717633195604\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 326\n",
      "total reward: 75.02766459269844\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 327\n",
      "total reward: -14.011116556387941\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 328\n",
      "total reward: 3.701576710274371\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 329\n",
      "total reward: 118.09608823756757\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 330\n",
      "total reward: 172.58772280962418\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 331\n",
      "total reward: 83.11495478679718\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 332\n",
      "total reward: 191.09638889269297\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 333\n",
      "total reward: 128.01695970095616\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 334\n",
      "total reward: 144.884703837003\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 335\n",
      "total reward: 145.6791360603734\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 336\n",
      "total reward: 126.61008295960244\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 337\n",
      "total reward: 163.1436657959454\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 338\n",
      "total reward: 160.49689357439655\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 339\n",
      "total reward: 115.7797257446567\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 340\n",
      "total reward: 141.62825031221445\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 341\n",
      "total reward: 164.10983203526789\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 342\n",
      "total reward: 73.19661821088069\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 343\n",
      "total reward: 119.83283067417786\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 344\n",
      "total reward: 161.39096893201582\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 345\n",
      "total reward: 116.28193422075306\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 346\n",
      "total reward: 81.42025817265852\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 347\n",
      "total reward: 205.5565097128613\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 348\n",
      "total reward: 155.1240634831843\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 349\n",
      "total reward: 198.60367386785808\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 350\n",
      "total reward: 58.310091204236656\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 351\n",
      "total reward: 103.88552450963647\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 352\n",
      "total reward: 75.6391872235912\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 353\n",
      "total reward: 63.93859478698226\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 354\n",
      "total reward: 9.293779889550688\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 355\n",
      "total reward: -56.852384015168425\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 356\n",
      "total reward: -1.3735229922562002\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 357\n",
      "total reward: 32.9267659350635\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 358\n",
      "total reward: 20.119745988377048\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 359\n",
      "total reward: 99.11692571006417\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 360\n",
      "total reward: 5.741443492926863\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 361\n",
      "total reward: 10.732928312641949\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 362\n",
      "total reward: 94.42327153762663\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 363\n",
      "total reward: -3.3990651857398126\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 364\n",
      "total reward: 59.1970745824082\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 365\n",
      "total reward: 17.131708483952256\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 366\n",
      "total reward: 44.477197735352945\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 367\n",
      "total reward: 5.404017935420307\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 368\n",
      "total reward: 58.5790313796814\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 369\n",
      "total reward: -42.863440698401135\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 370\n",
      "total reward: 48.462493682874694\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 371\n",
      "total reward: 31.107698871068717\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 372\n",
      "total reward: 44.344532967356194\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 373\n",
      "total reward: -20.48276646506081\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 374\n",
      "total reward: -1.5720431358112117\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 375\n",
      "total reward: 51.17394304961957\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 376\n",
      "total reward: 57.20465322068004\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 377\n",
      "total reward: 127.61612763307917\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 378\n",
      "total reward: 13.755751840416249\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 379\n",
      "total reward: 62.24919987539931\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 380\n",
      "total reward: 44.881027270114494\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 381\n",
      "total reward: 88.99507497377496\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 382\n",
      "total reward: 6.744684075779296\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 383\n",
      "total reward: -19.14346770209341\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 384\n",
      "total reward: 72.80760082718581\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 385\n",
      "total reward: 52.50570475213168\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 386\n",
      "total reward: 162.12979023507177\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 387\n",
      "total reward: 157.20532978214402\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 388\n",
      "total reward: 107.85243277809234\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 389\n",
      "total reward: 51.090213094693276\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 390\n",
      "total reward: 178.7386965142084\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 391\n",
      "total reward: 87.87399358502677\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 392\n",
      "total reward: 36.188009538366835\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 393\n",
      "total reward: 192.28605120871532\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 394\n",
      "total reward: 87.83663147349705\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 395\n",
      "total reward: 48.29367456665357\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 396\n",
      "total reward: -22.579786075226142\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 397\n",
      "total reward: 147.70294840180208\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 398\n",
      "total reward: 54.2865200266927\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 399\n",
      "total reward: 69.64555358370252\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 400\n",
      "total reward: 121.70246923538562\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 401\n",
      "total reward: 116.02033432097244\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 402\n",
      "total reward: 46.390413246722005\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 403\n",
      "total reward: 128.59134730597236\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 404\n",
      "total reward: 86.2309072505399\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 405\n",
      "total reward: -2.403805134956653\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 406\n",
      "total reward: 57.956795047538094\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 407\n",
      "total reward: 44.63763675941059\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 408\n",
      "total reward: 36.227481907565526\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 409\n",
      "total reward: 147.3278199058935\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 410\n",
      "total reward: 47.252895948133116\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 411\n",
      "total reward: -4.354387708001326\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 412\n",
      "total reward: 118.73679063911266\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 413\n",
      "total reward: 65.60480334175762\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 414\n",
      "total reward: 96.93031828474338\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 415\n",
      "total reward: 78.20866354008739\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 416\n",
      "total reward: 14.725321600457143\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 417\n",
      "total reward: 158.6235058377965\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 418\n",
      "total reward: 67.76971388868789\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 419\n",
      "total reward: 112.79766052759098\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 420\n",
      "total reward: 124.28412825772924\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 421\n",
      "total reward: 125.41235557229194\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 422\n",
      "total reward: 114.87905469386092\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 423\n",
      "total reward: 139.21976431823876\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 424\n",
      "total reward: 71.80474053703998\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 425\n",
      "total reward: 130.11736473342881\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 426\n",
      "total reward: 80.65145277983652\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 427\n",
      "total reward: 104.99508524856532\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 428\n",
      "total reward: 74.01942072674068\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 429\n",
      "total reward: 88.8206972577336\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 430\n",
      "total reward: 86.35217881567564\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 431\n",
      "total reward: 100.89711164893507\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 432\n",
      "total reward: 54.953779675357374\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 433\n",
      "total reward: 67.98122630500902\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 434\n",
      "total reward: 161.91524172841054\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 435\n",
      "total reward: 112.052911247288\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 436\n",
      "total reward: 121.30933454296995\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 437\n",
      "total reward: 116.44768227685435\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 438\n",
      "total reward: 156.38183966016902\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 439\n",
      "total reward: 190.01793527487501\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 440\n",
      "total reward: 106.69756812646006\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 441\n",
      "total reward: -5.028766194180067\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 442\n",
      "total reward: 79.27625856905988\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 443\n",
      "total reward: 69.67271873490313\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 444\n",
      "total reward: 84.96543317624169\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 445\n",
      "total reward: 114.72851501840857\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 446\n",
      "total reward: 167.35279003488947\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 447\n",
      "total reward: 82.86557342608488\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 448\n",
      "total reward: 42.69396158832601\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 449\n",
      "total reward: 65.4033972177385\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 450\n",
      "total reward: 118.90441483464765\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 451\n",
      "total reward: 142.78320111379213\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 452\n",
      "total reward: 119.62536509701243\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 453\n",
      "total reward: 127.10471990342059\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 454\n",
      "total reward: 126.22766785253317\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 455\n",
      "total reward: 93.60141599424492\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 456\n",
      "total reward: 75.91208612416274\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 457\n",
      "total reward: 166.7410011686502\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 458\n",
      "total reward: 119.77226660239599\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 459\n",
      "total reward: 113.73230139613989\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 460\n",
      "total reward: 120.10268229301806\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 461\n",
      "total reward: 148.65866365690687\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 462\n",
      "total reward: 91.31988672875147\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 463\n",
      "total reward: 128.25560729056897\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 464\n",
      "total reward: 113.6209316181819\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 465\n",
      "total reward: 86.29938942567166\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 466\n",
      "total reward: 67.80119423567044\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 467\n",
      "total reward: 104.41757533466526\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 468\n",
      "total reward: 158.87448500383692\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 469\n",
      "total reward: 72.06172385332678\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 470\n",
      "total reward: 143.19086465873212\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 471\n",
      "total reward: 196.0711118824317\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 472\n",
      "total reward: 157.45965326873477\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 473\n",
      "total reward: 202.78554070701273\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 474\n",
      "total reward: 196.16808222752385\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 475\n",
      "total reward: 83.96425604308097\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 476\n",
      "total reward: 116.46221072662173\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 477\n",
      "total reward: 78.69354414391857\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 478\n",
      "total reward: 139.8695154268753\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 479\n",
      "total reward: 62.41712016447393\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 480\n",
      "total reward: 97.79282468554084\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 481\n",
      "total reward: 87.5929661237218\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 482\n",
      "total reward: 90.81496400069713\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 483\n",
      "total reward: 117.437329470824\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 484\n",
      "total reward: 41.98491798565608\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 485\n",
      "total reward: 14.888994699809967\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 486\n",
      "total reward: 65.41793909212822\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 487\n",
      "total reward: 87.9454012037063\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 488\n",
      "total reward: 73.21205075103467\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 489\n",
      "total reward: 104.8656353445046\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 490\n",
      "total reward: 165.92309221721337\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 491\n",
      "total reward: 92.76261779004356\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 492\n",
      "total reward: 127.15020827109295\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 493\n",
      "total reward: 45.418337995475824\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 494\n",
      "total reward: 56.505542823866286\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 495\n",
      "total reward: 129.4714066307044\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 496\n",
      "total reward: -14.996343965458017\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 497\n",
      "total reward: 115.2354582056017\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 498\n",
      "total reward: -43.16582652525358\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 499\n",
      "total reward: 96.55706441039332\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 500\n",
      "total reward: 64.69097016689543\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 501\n",
      "total reward: 90.40944093669643\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 502\n",
      "total reward: 75.97292075154043\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 503\n",
      "total reward: 32.568155030519165\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 504\n",
      "total reward: 98.23713164526272\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 505\n",
      "total reward: 116.82875150631729\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 506\n",
      "total reward: 95.12172457478614\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 507\n",
      "total reward: 122.41954035929051\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 508\n",
      "total reward: 70.2681605894209\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 509\n",
      "total reward: 146.40158891138674\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 510\n",
      "total reward: 110.21801643958266\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 511\n",
      "total reward: 29.11868798776972\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 512\n",
      "total reward: 78.35848732828508\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 513\n",
      "total reward: 57.041516421239606\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 514\n",
      "total reward: 82.6684813677179\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 515\n",
      "total reward: 22.963486477485368\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 516\n",
      "total reward: 79.77545619804529\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 517\n",
      "total reward: 106.15582133088961\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 518\n",
      "total reward: 103.19601866809656\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 519\n",
      "total reward: 68.41179328697571\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 520\n",
      "total reward: 81.82961126559928\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 521\n",
      "total reward: 93.504209197836\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 522\n",
      "total reward: 146.43922713201306\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 523\n",
      "total reward: 109.11751848205206\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 524\n",
      "total reward: 129.12178658926763\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 525\n",
      "total reward: 28.382475622630224\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 526\n",
      "total reward: 50.07646394801031\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 527\n",
      "total reward: 63.11610541626009\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 528\n",
      "total reward: 142.5679609407396\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 529\n",
      "total reward: 126.92775602951883\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 530\n",
      "total reward: 123.20990878363946\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 531\n",
      "total reward: 148.34069327657772\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 532\n",
      "total reward: 116.46371037804713\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 533\n",
      "total reward: 139.18810123958795\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 534\n",
      "total reward: 110.95355093070228\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 535\n",
      "total reward: 98.03305914566077\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 536\n",
      "total reward: 137.65843404747986\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 537\n",
      "total reward: 143.7675701308949\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 538\n",
      "total reward: 86.17963124554159\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 539\n",
      "total reward: 123.06909431545678\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 540\n",
      "total reward: 111.60694217200523\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 541\n",
      "total reward: 136.02731280740576\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 542\n",
      "total reward: 124.0544489571389\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 543\n",
      "total reward: 69.68517169685079\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 544\n",
      "total reward: 129.00093343921563\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 545\n",
      "total reward: 165.04779852438958\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 546\n",
      "total reward: 93.34859505347184\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 547\n",
      "total reward: 37.74735607911304\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 548\n",
      "total reward: 120.69910910881813\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 549\n",
      "total reward: 184.2867851435292\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 550\n",
      "total reward: 129.4422869334536\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 551\n",
      "total reward: 99.54778732261954\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 552\n",
      "total reward: 165.2267615082464\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 553\n",
      "total reward: 173.6695062361831\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 554\n",
      "total reward: 110.84096293702629\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 555\n",
      "total reward: 111.4893330349112\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 556\n",
      "total reward: 133.97065617986166\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 557\n",
      "total reward: 109.07224265855123\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 558\n",
      "total reward: 85.75289024394863\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 559\n",
      "total reward: 124.21950109799512\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 560\n",
      "total reward: 34.3339377541542\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 561\n",
      "total reward: 80.91969528245515\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 562\n",
      "total reward: 127.64416100887846\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 563\n",
      "total reward: 114.45926841935143\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 564\n",
      "total reward: 98.6551526090013\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 565\n",
      "total reward: 78.08968225487695\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 566\n",
      "total reward: 148.32027523915673\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 567\n",
      "total reward: 171.5777986380658\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 568\n",
      "total reward: 179.44286927074327\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 569\n",
      "total reward: 145.59332151237632\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 570\n",
      "total reward: 157.11486430925814\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 571\n",
      "total reward: 127.75329467917534\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 572\n",
      "total reward: 107.27661154087866\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 573\n",
      "total reward: 82.18214110366864\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 574\n",
      "total reward: 69.5225517427474\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 575\n",
      "total reward: 28.13077419956634\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 576\n",
      "total reward: 147.1827294003412\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 577\n",
      "total reward: 137.07311844236168\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 578\n",
      "total reward: 96.7592952260497\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 579\n",
      "total reward: 68.21807436681678\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 580\n",
      "total reward: 131.1093318755771\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 581\n",
      "total reward: 187.4109122357107\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 582\n",
      "total reward: 143.4054670800122\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 583\n",
      "total reward: 126.95249820078635\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 584\n",
      "total reward: 83.1826885294115\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 585\n",
      "total reward: 25.46081916659152\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 586\n",
      "total reward: 24.597050089676564\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 587\n",
      "total reward: 71.7982161282348\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 588\n",
      "total reward: 29.35679767928931\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 589\n",
      "total reward: 100.98585565024972\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 590\n",
      "total reward: 74.35057515067231\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 591\n",
      "total reward: 136.3746783516396\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 592\n",
      "total reward: 71.53764246875731\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 593\n",
      "total reward: 126.6101540939203\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 594\n",
      "total reward: -12.685373727590083\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 595\n",
      "total reward: 47.80306354661904\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 596\n",
      "total reward: 92.77899137492261\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 597\n",
      "total reward: -1.2031704203478175\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 598\n",
      "total reward: -0.46074667180271733\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 599\n",
      "total reward: 37.3326107611356\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 600\n",
      "total reward: 119.09658165609532\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 601\n",
      "total reward: 119.93704013947107\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 602\n",
      "total reward: 49.83290785444024\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 603\n",
      "total reward: 21.311143736346835\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 604\n",
      "total reward: -21.85507795506908\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 605\n",
      "total reward: -132.1438745341396\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 606\n",
      "total reward: -36.0979337193613\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 607\n",
      "total reward: -9.293083593792847\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 608\n",
      "total reward: 15.772829391381528\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 609\n",
      "total reward: -65.87185329339249\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 610\n",
      "total reward: 22.190068894472343\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 611\n",
      "total reward: 53.039729713883034\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 612\n",
      "total reward: -7.346259304527843\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 613\n",
      "total reward: 110.57470154429765\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 614\n",
      "total reward: 16.00936789217669\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 615\n",
      "total reward: 82.72270371020157\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 616\n",
      "total reward: 71.21766969404784\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 617\n",
      "total reward: 80.52252500016442\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 618\n",
      "total reward: 128.30139183115102\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 619\n",
      "total reward: 42.21771668802745\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 620\n",
      "total reward: 162.4683966410421\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 621\n",
      "total reward: 122.5996284431994\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 622\n",
      "total reward: 149.85998592796872\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 623\n",
      "total reward: 112.01648916664354\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 624\n",
      "total reward: 94.8058819327143\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 625\n",
      "total reward: 106.44130784343697\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 626\n",
      "total reward: 112.77783644695715\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 627\n",
      "total reward: 118.48947511256127\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 628\n",
      "total reward: 86.1691422935252\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 629\n",
      "total reward: 141.31700495602126\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 630\n",
      "total reward: 57.10175026047475\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 631\n",
      "total reward: 108.02161287497381\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 632\n",
      "total reward: 113.77991491559638\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 633\n",
      "total reward: 137.90519978557293\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 634\n",
      "total reward: 92.01001399203274\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 635\n",
      "total reward: 117.33699528042095\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 636\n",
      "total reward: 91.62306665516158\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 637\n",
      "total reward: 68.19568318253087\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 638\n",
      "total reward: 47.58834374010303\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 639\n",
      "total reward: 108.36251679451871\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 640\n",
      "total reward: 154.18944087196826\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 641\n",
      "total reward: 154.05514208716272\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 642\n",
      "total reward: 71.34133230722048\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 643\n",
      "total reward: 123.59582033757115\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 644\n",
      "total reward: 19.295549852860894\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 645\n",
      "total reward: 99.75175843591265\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 646\n",
      "total reward: 117.5169921516741\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 647\n",
      "total reward: 137.41021909357636\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 648\n",
      "total reward: 142.02326934718846\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 649\n",
      "total reward: 62.411408362787455\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 650\n",
      "total reward: 195.4496443460354\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 651\n",
      "total reward: 152.8877073961408\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 652\n",
      "total reward: 131.23894049281554\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 653\n",
      "total reward: 176.85971751660054\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 654\n",
      "total reward: 85.99827582612508\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 655\n",
      "total reward: 88.65159827101809\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 656\n",
      "total reward: 112.29465192826329\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 657\n",
      "total reward: 50.2793588190238\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 658\n",
      "total reward: 93.03945154885957\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 659\n",
      "total reward: 94.68782281871206\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 660\n",
      "total reward: 121.05436346531891\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 661\n",
      "total reward: 147.3432691159356\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 662\n",
      "total reward: 155.67798626765747\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 663\n",
      "total reward: 156.827599869078\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 664\n",
      "total reward: 107.86668679673137\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 665\n",
      "total reward: 76.36522713306616\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 666\n",
      "total reward: 115.25070924601994\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 667\n",
      "total reward: 42.58204337663692\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 668\n",
      "total reward: 139.91372458084766\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 669\n",
      "total reward: 90.85728915944443\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 670\n",
      "total reward: 109.15693397530646\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 671\n",
      "total reward: 103.79340530142213\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 672\n",
      "total reward: 136.65275983518114\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 673\n",
      "total reward: 117.80608706510567\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 674\n",
      "total reward: 32.458711884421874\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 675\n",
      "total reward: 43.659239021124876\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 676\n",
      "total reward: 98.32149864597713\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 677\n",
      "total reward: 97.55373556880606\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 678\n",
      "total reward: 1.3148676779935138\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 679\n",
      "total reward: 41.258739105556714\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 680\n",
      "total reward: 48.776064375630526\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 681\n",
      "total reward: -11.322746516129211\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 682\n",
      "total reward: 98.88225232427415\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 683\n",
      "total reward: 80.88912299438942\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 684\n",
      "total reward: 39.10255733997586\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 685\n",
      "total reward: 92.07949150740687\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 686\n",
      "total reward: 107.76193828179501\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 687\n",
      "total reward: 134.4750999942436\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 688\n",
      "total reward: 62.35857711600186\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 689\n",
      "total reward: 39.48991003527501\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 690\n",
      "total reward: 72.10488094677119\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 691\n",
      "total reward: 10.784150126094252\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 692\n",
      "total reward: 47.59913043722302\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 693\n",
      "total reward: 97.56467193516563\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 694\n",
      "total reward: 73.07363571842886\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 695\n",
      "total reward: 58.80114552263544\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 696\n",
      "total reward: 13.714445486864665\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 697\n",
      "total reward: 101.51609768363507\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 698\n",
      "total reward: 50.963819041650694\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 699\n",
      "total reward: 85.35754049548893\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 700\n",
      "total reward: 86.46442422182805\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 701\n",
      "total reward: 108.26273248277235\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 702\n",
      "total reward: 51.107276945412636\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 703\n",
      "total reward: 60.911923951144544\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 704\n",
      "total reward: 21.363322841701454\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 705\n",
      "total reward: 44.92042309550871\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 706\n",
      "total reward: 54.22324460908351\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 707\n",
      "total reward: 35.215549256410426\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 708\n",
      "total reward: 65.03458290457925\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 709\n",
      "total reward: 90.95581804507785\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 710\n",
      "total reward: 52.13204088014545\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 711\n",
      "total reward: 8.641420756330636\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 712\n",
      "total reward: 23.90345748331908\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 713\n",
      "total reward: 59.00492855957141\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 714\n",
      "total reward: 75.80193179271888\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 715\n",
      "total reward: 105.73087790233612\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 716\n",
      "total reward: 43.837694916374666\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 717\n",
      "total reward: 79.21227135104473\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 718\n",
      "total reward: 152.5877782706258\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 719\n",
      "total reward: 95.81030491986027\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 720\n",
      "total reward: 139.62303287138172\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 721\n",
      "total reward: 76.94886633680221\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 722\n",
      "total reward: 54.690790231399575\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 723\n",
      "total reward: 73.1580760391727\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 724\n",
      "total reward: 81.88743968001899\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 725\n",
      "total reward: 86.73426225163988\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 726\n",
      "total reward: 102.98041489684795\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 727\n",
      "total reward: 107.4869961692956\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 728\n",
      "total reward: 78.05819702753317\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 729\n",
      "total reward: 37.27098745834556\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 730\n",
      "total reward: 23.830219643352635\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 731\n",
      "total reward: 9.709448855830823\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 732\n",
      "total reward: 102.32077780260396\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 733\n",
      "total reward: 86.8654296752216\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 734\n",
      "total reward: 100.02373694799051\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 735\n",
      "total reward: 91.68034518911963\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 736\n",
      "total reward: 59.06174487486307\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 737\n",
      "total reward: 89.91610457566131\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 738\n",
      "total reward: 113.31196648768639\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 739\n",
      "total reward: 115.29782225686476\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 740\n",
      "total reward: 110.97781494903268\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 741\n",
      "total reward: 142.71325945203787\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 742\n",
      "total reward: 105.22515343030808\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 743\n",
      "total reward: 38.64929203027831\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 744\n",
      "total reward: 103.04859866109805\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 745\n",
      "total reward: 100.67856595512482\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 746\n",
      "total reward: 74.48663694154331\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 747\n",
      "total reward: 18.302503487973482\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 748\n",
      "total reward: 88.51473664823963\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 749\n",
      "total reward: 37.81199596827148\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 750\n",
      "total reward: 27.763655587996396\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 751\n",
      "total reward: 59.44251503497492\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 752\n",
      "total reward: 97.1604534974936\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 753\n",
      "total reward: 82.11705239513407\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 754\n",
      "total reward: 6.32928884319276\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 755\n",
      "total reward: 190.9295530037406\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 756\n",
      "total reward: 102.98299236822336\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 757\n",
      "total reward: 27.88718975526022\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 758\n",
      "total reward: 91.02700971690928\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 759\n",
      "total reward: 90.60498917739721\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 760\n",
      "total reward: 64.05582252651942\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 761\n",
      "total reward: 53.18777578262047\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 762\n",
      "total reward: 99.38887546665275\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 763\n",
      "total reward: 88.32260277658936\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 764\n",
      "total reward: 93.70771989651925\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 765\n",
      "total reward: 96.80474289748952\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 766\n",
      "total reward: 132.62716610626754\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 767\n",
      "total reward: 60.46557731389446\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 768\n",
      "total reward: 129.38606184764902\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 769\n",
      "total reward: 150.76084820137774\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 770\n",
      "total reward: 96.67941848214475\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 771\n",
      "total reward: 89.45965565956774\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 772\n",
      "total reward: 92.577958134927\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 773\n",
      "total reward: 86.67779698025345\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 774\n",
      "total reward: 85.52420738880483\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 775\n",
      "total reward: 88.3637042895027\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 776\n",
      "total reward: 113.24998759021443\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 777\n",
      "total reward: 146.41344504026418\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 778\n",
      "total reward: 48.88966871966804\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 779\n",
      "total reward: 48.68999280386906\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 780\n",
      "total reward: 58.33408061977441\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 781\n",
      "total reward: 61.06591544214089\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 782\n",
      "total reward: 89.41752915651801\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 783\n",
      "total reward: 76.47820254330804\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 784\n",
      "total reward: 9.175217002932737\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 785\n",
      "total reward: 81.98612826321533\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 786\n",
      "total reward: 37.990217505999794\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 787\n",
      "total reward: 101.30798210818239\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 788\n",
      "total reward: 68.30484931555327\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 789\n",
      "total reward: 46.32811124737559\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 790\n",
      "total reward: 10.03056446207287\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 791\n",
      "total reward: 69.2771223697656\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 792\n",
      "total reward: 9.570827339371856\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 793\n",
      "total reward: 18.885331369271363\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 794\n",
      "total reward: 58.95388703302557\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 795\n",
      "total reward: 79.15577706419347\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 796\n",
      "total reward: 87.55958326349992\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 797\n",
      "total reward: 65.25970686635677\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 798\n",
      "total reward: 39.59082527023245\n",
      "number of steps: 128\n",
      "---------------\n",
      "finished episode: 799\n",
      "total reward: 62.7019811256217\n",
      "number of steps: 128\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "agent.fit(800, 128, 4, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b7b050",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mall_rewards)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(agent.all_rewards)\n",
    "plt.xlabel('episode')\n",
    "plt.ylabel('reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43e88c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3354646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_agent('lunarlander_agent.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba901bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  32,  64,  96, 128, 160, 192])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as T \n",
    "start = T.arange(0, 200, 32)\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a1abca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 14, 164,  68,  64, 148, 194, 132,  93,  65,  16, 139,  46, 127,  33,\n",
       "         60, 147,  84,  30,  39, 190, 126,  99,   9,  54,  12, 171, 178,  55,\n",
       "         81, 125, 195, 168,  49, 150,  36, 112, 143, 116,  24,  77,  41,  11,\n",
       "        142, 106, 180, 124, 121,  83,  88, 109,  52,  47,  13,  80, 128, 151,\n",
       "         66, 113, 182, 166,  32,  22, 181, 174, 119, 107, 122,  94, 146,   3,\n",
       "         27, 193, 196, 189, 101,  69,  10, 154, 131,  58,  34, 117, 158,   1,\n",
       "         44, 111,   7,  98, 161,  31,  95, 159,   4,  97,   6, 179,  25, 173,\n",
       "         57, 176, 165, 110,   0, 155,  71,  48,  62,  42, 149,  18,  59,  53,\n",
       "         19, 197,  75, 185,  70, 140, 183, 120, 198, 138, 141,  17, 103, 162,\n",
       "        135, 100,  56,  85, 156,  76, 170,  26, 115,  45,  23,  91, 108,  86,\n",
       "         37,  61, 188, 114, 175,  43,  29, 157,  38, 129, 163, 199,   2,  15,\n",
       "        137, 136, 192,  35,  90, 145,  21, 105, 104,  20,   8, 123,  82, 160,\n",
       "         96,  28,  74, 186, 130,  72,   5, 144, 102, 187, 167,  63,  87, 153,\n",
       "        184, 177, 169, 118, 172,  73,  92, 134,  79, 152,  40,  51,  89,  78,\n",
       "        133,  50,  67, 191])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = T.randperm(200)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [indices[i:i+32] for i in start]\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff3f9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 91,  18,  74,  50, 100, 118, 178, 122,  93,  61,  55,  13, 128, 198,\n",
      "         16, 154,  54,  65, 184,  12, 171,  53,  23,  64, 132, 175, 101, 176,\n",
      "         20, 170, 144, 181])\n",
      "tensor([ 15, 195,   6, 165, 127,   2,   4,  42,  37, 114,  66, 147, 191, 143,\n",
      "         89, 194,  83, 193, 157, 167, 106,  35, 174, 152, 185,  36, 109,  21,\n",
      "         68,  26,  75, 110])\n",
      "tensor([ 71, 146,   5,  57,  62, 159, 145, 116, 151, 112,  11, 180,  41,  70,\n",
      "          0,  52,  90,  27, 108,  80,  82, 150,  73, 136, 173, 119,  63, 115,\n",
      "        111, 129,  10,  72])\n",
      "tensor([190,  95, 168,  88, 197,  97, 158, 130,   1,  25, 131,  59,  78,  87,\n",
      "        113,  77, 188,  44,  92,  43,  56,  46,  28,  33, 124,  67,  86,  40,\n",
      "        186,  14,  69, 156])\n",
      "tensor([ 39, 133,  81,  49, 135, 117,   3, 126,  24,  34,  94,  76,  47, 155,\n",
      "        172, 164,  51,  96, 120, 182,  48, 105, 103, 125,  22, 148, 161, 189,\n",
      "        149, 107, 160, 169])\n",
      "tensor([137, 141,  19, 153, 139, 196, 140, 121,  45, 177,  79, 138,  29,  31,\n",
      "          8,  99,  84,  58, 183, 123,  17, 166, 104,  32,  38, 192, 179,  98,\n",
      "        142,  30,  85,   7])\n",
      "tensor([ 60,   9, 187, 134, 102, 162, 199, 163])\n"
     ]
    }
   ],
   "source": [
    "for batch in batches:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fad93f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.shape.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ba068d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "332d329b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810dc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
