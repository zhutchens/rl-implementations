{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaae308b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.ppo import Agent, evaluate\n",
    "import torch \n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers.vector import NormalizeObservation, NormalizeReward, NumpyToTorch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1f3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(render_mode: str = 'human'):\n",
    "    env = gym.make_vec('LunarLander-v3', render_mode = render_mode)\n",
    "    env = NormalizeObservation(env)\n",
    "    env = NumpyToTorch(env)\n",
    "    mean = np.load('environment/lunarlander_env_mean.npy')\n",
    "    var = np.load('environment/lunarlander_env_var.npy')\n",
    "    env.env.obs_rms.mean = mean\n",
    "    env.env.obs_rms.var = var\n",
    "    env.env.training = False\n",
    "\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199d11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation reward: -332.99387425686507\n",
      "evaluation reward: -213.4456415263088\n",
      "evaluation reward: -260.860932002946\n",
      "average reward: -269.10014926203996\n"
     ]
    }
   ],
   "source": [
    "agent = Agent.load_agent('models/lunarlander_agent.pt', device)\n",
    "agent.actor.eval()\n",
    "agent.critic.eval()\n",
    "env = create_env()\n",
    "\n",
    "evaluate(env, 3, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a481b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abdee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation reward: -327.08922344517464\n",
      "evaluation reward: -288.5334575441909\n",
      "evaluation reward: -239.27111566823098\n",
      "evaluation reward: -124.4447098434947\n",
      "evaluation reward: -147.5117326308311\n",
      "evaluation reward: -234.34107852663993\n",
      "evaluation reward: -185.13312430407802\n",
      "evaluation reward: -130.95480486085646\n",
      "evaluation reward: -195.8126801165384\n",
      "evaluation reward: -165.132379877039\n",
      "evaluation reward: -190.6839605719879\n",
      "evaluation reward: -150.3030154939135\n",
      "evaluation reward: -193.81921096064593\n",
      "evaluation reward: -189.48264577673683\n",
      "evaluation reward: -192.90463147576946\n",
      "evaluation reward: -125.9688701500249\n",
      "evaluation reward: -202.61805112112307\n",
      "evaluation reward: -164.31012313511593\n",
      "evaluation reward: -286.54647428406327\n",
      "evaluation reward: -578.1254237871112\n",
      "evaluation reward: -171.23436464647597\n",
      "evaluation reward: -147.60688900695348\n",
      "evaluation reward: -230.58291221054444\n",
      "evaluation reward: -150.00982786060356\n",
      "evaluation reward: -139.21013150318234\n",
      "evaluation reward: -149.16265381158482\n",
      "evaluation reward: -134.38047424344597\n",
      "evaluation reward: -98.71332856535301\n",
      "evaluation reward: -531.9870812597276\n",
      "evaluation reward: -292.2251642120251\n",
      "evaluation reward: -347.25782487164105\n",
      "evaluation reward: -124.48866724178322\n",
      "evaluation reward: -285.21346673495486\n",
      "evaluation reward: -247.19196194564418\n",
      "evaluation reward: -187.20043866833464\n",
      "evaluation reward: -557.2240310281793\n",
      "evaluation reward: -118.746999264608\n",
      "evaluation reward: -458.5716320139712\n",
      "evaluation reward: -158.76386089821375\n",
      "evaluation reward: -600.8838785274229\n",
      "evaluation reward: -143.56907774038308\n",
      "evaluation reward: -153.83477725624994\n",
      "evaluation reward: -102.04197244424357\n",
      "evaluation reward: -113.08522932183315\n",
      "evaluation reward: -154.99552906957325\n",
      "evaluation reward: -121.60193397399722\n",
      "evaluation reward: -177.11455003390793\n",
      "evaluation reward: -139.99816336655033\n",
      "evaluation reward: -469.4747497130069\n",
      "evaluation reward: -126.08939622093702\n",
      "evaluation reward: -196.51003121796634\n",
      "evaluation reward: -121.66086763966396\n",
      "evaluation reward: -681.0685555855861\n",
      "evaluation reward: -130.27412707912123\n",
      "evaluation reward: -152.54076608446573\n",
      "evaluation reward: -108.0112724878794\n",
      "evaluation reward: -127.17746147370573\n",
      "evaluation reward: -153.48404300439975\n",
      "evaluation reward: -119.0390847796101\n",
      "evaluation reward: -162.72779042389726\n",
      "evaluation reward: -204.53723099527133\n",
      "evaluation reward: -118.49093491730837\n",
      "evaluation reward: -111.69798170918666\n",
      "evaluation reward: -166.35991485236173\n",
      "evaluation reward: -124.80878347075861\n",
      "evaluation reward: -147.2159258835582\n",
      "evaluation reward: -560.7662788239254\n",
      "evaluation reward: -238.7929535274416\n",
      "evaluation reward: -145.21613687590497\n",
      "evaluation reward: -162.26926961726076\n",
      "evaluation reward: -113.43654935424826\n",
      "evaluation reward: -147.99971212501845\n",
      "evaluation reward: -148.87848212243557\n",
      "evaluation reward: -552.1425566875494\n",
      "evaluation reward: -131.37135603925054\n",
      "evaluation reward: -117.75043245443\n",
      "evaluation reward: -185.04294178553386\n",
      "evaluation reward: -165.64382295438162\n",
      "evaluation reward: -106.67267824847985\n",
      "evaluation reward: -169.81530661014716\n",
      "evaluation reward: -135.84824822916465\n",
      "evaluation reward: -91.97145904582811\n",
      "evaluation reward: -112.25970025995109\n",
      "evaluation reward: -111.68300040107384\n",
      "evaluation reward: -161.92055540351421\n",
      "evaluation reward: -129.8685571906963\n",
      "evaluation reward: -140.65484825246213\n",
      "evaluation reward: -163.28653872775018\n",
      "evaluation reward: -166.71912202293964\n",
      "evaluation reward: -143.11243633717731\n",
      "evaluation reward: -149.5777521092238\n",
      "evaluation reward: -176.7361548586041\n",
      "evaluation reward: -146.96837863335134\n",
      "evaluation reward: -172.36111579510836\n",
      "evaluation reward: -157.1720593703583\n",
      "evaluation reward: -175.66073243101675\n",
      "evaluation reward: -86.77638952600049\n",
      "evaluation reward: -304.06412784825363\n",
      "evaluation reward: -139.76557640438872\n",
      "evaluation reward: -123.00454298766306\n",
      "average reward: -199.06262225894173\n"
     ]
    }
   ],
   "source": [
    "env = create_env('rgb_array')\n",
    "evaluate(env, 100, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6b0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
