{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaae308b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.ppo import Agent, evaluate\n",
    "import torch \n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers.vector import NumpyToTorch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1f3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(render_mode: str = 'human'):\n",
    "    env = gym.make_vec('LunarLander-v3', render_mode = render_mode)\n",
    "    env = NumpyToTorch(env)\n",
    "\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199d11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation reward: 267.6382861012411\n",
      "evaluation reward: 242.05109553856823\n",
      "evaluation reward: 277.16349176177346\n",
      "average reward: 262.2842911338609\n"
     ]
    }
   ],
   "source": [
    "agent = Agent.load_agent('models/lunarlander_agent.pt', device)\n",
    "agent.actor.eval()\n",
    "agent.critic.eval()\n",
    "env = create_env()\n",
    "\n",
    "evaluate(env, 3, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a481b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abdee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation reward: 262.5747043291117\n",
      "evaluation reward: 261.8672607022617\n",
      "evaluation reward: 286.1018743811111\n",
      "evaluation reward: 261.77590037724144\n",
      "evaluation reward: 263.1245100811454\n",
      "evaluation reward: 298.9572241867387\n",
      "evaluation reward: 304.1029325650778\n",
      "evaluation reward: 276.8158851284322\n",
      "evaluation reward: 249.89366123394282\n",
      "evaluation reward: 291.33149775524885\n",
      "evaluation reward: 269.5535478974354\n",
      "evaluation reward: 272.7279249743727\n",
      "evaluation reward: 280.02131150318826\n",
      "evaluation reward: 274.11574971228686\n",
      "evaluation reward: 306.96222514896914\n",
      "evaluation reward: 302.5195611927991\n",
      "evaluation reward: 261.3171457897505\n",
      "evaluation reward: 303.08448717305123\n",
      "evaluation reward: 275.8715725907149\n",
      "evaluation reward: 283.3515855310328\n",
      "evaluation reward: 274.4596502083976\n",
      "evaluation reward: 259.87865216204057\n",
      "evaluation reward: 235.62617463412695\n",
      "evaluation reward: 279.7345503793015\n",
      "evaluation reward: 294.49291565285614\n",
      "evaluation reward: 280.1611539813739\n",
      "evaluation reward: 287.1006197887384\n",
      "evaluation reward: 288.6180330149348\n",
      "evaluation reward: 254.18507298978284\n",
      "evaluation reward: 303.85995724926636\n",
      "evaluation reward: 298.78593313601306\n",
      "evaluation reward: 269.544984913313\n",
      "evaluation reward: 287.35150445399864\n",
      "evaluation reward: 272.3686362556527\n",
      "evaluation reward: 300.19493574147486\n",
      "evaluation reward: 281.452095928041\n",
      "evaluation reward: 265.007891515124\n",
      "evaluation reward: 253.57794806930664\n",
      "evaluation reward: 264.4153259556614\n",
      "evaluation reward: 289.0742763489452\n",
      "evaluation reward: 287.7840897194511\n",
      "evaluation reward: 265.50242784249986\n",
      "evaluation reward: 300.22279606977526\n",
      "evaluation reward: 310.81523363145357\n",
      "evaluation reward: 283.7313627863072\n",
      "evaluation reward: 294.84771515750515\n",
      "evaluation reward: 280.9420934009285\n",
      "evaluation reward: 295.14519174773125\n",
      "evaluation reward: 307.8062990156186\n",
      "evaluation reward: 271.50121819558717\n",
      "evaluation reward: 278.7826628731274\n",
      "evaluation reward: 230.99604519372338\n",
      "evaluation reward: 304.31564361380083\n",
      "evaluation reward: 266.07730983914564\n",
      "evaluation reward: 255.23692351088317\n",
      "evaluation reward: 273.2685509355501\n",
      "evaluation reward: 257.7878037017753\n",
      "evaluation reward: 268.9817135248961\n",
      "evaluation reward: 279.1203061139581\n",
      "evaluation reward: 307.62795423954293\n",
      "evaluation reward: 313.41496313295147\n",
      "evaluation reward: 261.95543980535365\n",
      "evaluation reward: 305.3350020114044\n",
      "evaluation reward: 295.13327050949727\n",
      "evaluation reward: 308.8720993225792\n",
      "evaluation reward: 297.82034818963473\n",
      "evaluation reward: 285.52662038059077\n",
      "evaluation reward: 275.51902452015963\n",
      "evaluation reward: 251.0772090002897\n",
      "evaluation reward: 259.15561698927183\n",
      "evaluation reward: 273.3903158739984\n",
      "evaluation reward: 289.2485636769869\n",
      "evaluation reward: 263.71489502144556\n",
      "evaluation reward: 274.964670452189\n",
      "evaluation reward: 291.90271338517266\n",
      "evaluation reward: 276.78801228945235\n",
      "evaluation reward: 288.0916961571207\n",
      "evaluation reward: 291.421866051087\n",
      "evaluation reward: 282.0233820909696\n",
      "evaluation reward: 277.2934051306544\n",
      "evaluation reward: 282.7369835728433\n",
      "evaluation reward: 274.01268621202445\n",
      "evaluation reward: 263.9980712410842\n",
      "evaluation reward: 290.15305295184186\n",
      "evaluation reward: 316.1604262775854\n",
      "evaluation reward: 255.80807254118153\n",
      "evaluation reward: 285.5463397322943\n",
      "evaluation reward: 237.9784976508141\n",
      "evaluation reward: 268.6702633071295\n",
      "evaluation reward: 297.5485462151739\n",
      "evaluation reward: 299.2569017711471\n",
      "evaluation reward: 302.61275248628783\n",
      "evaluation reward: 298.676411472833\n",
      "evaluation reward: 295.66775459523336\n",
      "evaluation reward: 307.66197792638934\n",
      "evaluation reward: 302.16246067615054\n",
      "evaluation reward: 262.57777188218745\n",
      "evaluation reward: 269.6106033301196\n",
      "evaluation reward: 277.41136620081284\n",
      "evaluation reward: 291.7602225756992\n",
      "average reward: 280.8911449235516\n"
     ]
    }
   ],
   "source": [
    "env = create_env('rgb_array')\n",
    "evaluate(env, 100, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6b0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
