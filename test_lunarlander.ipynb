{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaae308b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.ppo import Agent, evaluate\n",
    "import torch \n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import NormalizeReward, NormalizeObservation, NumpyToTorch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1f3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation reward: -105.14638607195657\n",
      "evaluation reward: -8.851630972484774\n",
      "evaluation reward: -21.153855516586166\n",
      "average reward: -45.05062418700917\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v3', render_mode = 'human')\n",
    "env = NormalizeObservation(env)\n",
    "env = NormalizeReward(env)\n",
    "env = NumpyToTorch(env)\n",
    "\n",
    "agent = Agent.load_agent('models/lunarlander_agent.pt', device)\n",
    "evaluate(env, 3, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a481b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abdee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation reward: -109.02977670691305\n",
      "evaluation reward: -10.736396082562042\n",
      "evaluation reward: -7.337742596367145\n",
      "evaluation reward: -7.499018893993982\n",
      "evaluation reward: -9.208457947772294\n",
      "evaluation reward: -8.563204148076704\n",
      "evaluation reward: -11.967989374717881\n",
      "evaluation reward: -9.997741721122345\n",
      "evaluation reward: -14.131529528320451\n",
      "evaluation reward: -12.227567995435468\n",
      "evaluation reward: -8.401308266113002\n",
      "evaluation reward: -13.417517707093594\n",
      "evaluation reward: -10.834685870626789\n",
      "evaluation reward: -10.830345387993038\n",
      "evaluation reward: -10.474949615804729\n",
      "evaluation reward: -19.60805190771164\n",
      "evaluation reward: -11.552783234191146\n",
      "evaluation reward: -11.530939195775705\n",
      "evaluation reward: -12.980527512257252\n",
      "evaluation reward: -11.821852955795102\n",
      "evaluation reward: -17.471843102665368\n",
      "evaluation reward: -11.234854799223626\n",
      "evaluation reward: -11.60182964680528\n",
      "evaluation reward: -16.48070364357183\n",
      "evaluation reward: -14.937820852416937\n",
      "evaluation reward: -14.763607784927657\n",
      "evaluation reward: -10.057603317217943\n",
      "evaluation reward: -24.43095798853296\n",
      "evaluation reward: -8.431841429362134\n",
      "evaluation reward: -23.029531191170364\n",
      "evaluation reward: -21.65923562991703\n",
      "evaluation reward: -13.211435598982762\n",
      "evaluation reward: -25.770982147432274\n",
      "evaluation reward: -23.037218686087883\n",
      "evaluation reward: -13.812299146102674\n",
      "evaluation reward: -21.443406095256346\n",
      "evaluation reward: -11.33534439170611\n",
      "evaluation reward: -25.041506431318847\n",
      "evaluation reward: -15.827598015343703\n",
      "evaluation reward: -11.761959922476263\n",
      "evaluation reward: -19.750437579125578\n",
      "evaluation reward: -14.760186582211738\n",
      "evaluation reward: -12.471450145091186\n",
      "evaluation reward: -12.509721949791603\n",
      "evaluation reward: -25.23875020948414\n",
      "evaluation reward: -13.047805605094798\n",
      "evaluation reward: -24.843482161619693\n",
      "evaluation reward: -15.767870124189656\n",
      "evaluation reward: -17.14218268344279\n",
      "evaluation reward: -17.059449755583746\n",
      "evaluation reward: -24.462188953718233\n",
      "evaluation reward: -10.280461879786124\n",
      "evaluation reward: -16.555978589259517\n",
      "evaluation reward: -15.750441993102115\n",
      "evaluation reward: -11.533005195678331\n",
      "evaluation reward: -21.61045842346143\n",
      "evaluation reward: -15.511659321695504\n",
      "evaluation reward: -16.035991765343113\n",
      "evaluation reward: -15.518000984064816\n",
      "evaluation reward: -27.214614994004265\n",
      "evaluation reward: -16.88325522647745\n",
      "evaluation reward: -15.547706352943084\n",
      "evaluation reward: -17.868467233816784\n",
      "evaluation reward: -13.081247999602107\n",
      "evaluation reward: -12.478122512757915\n",
      "evaluation reward: -14.169388853653466\n",
      "evaluation reward: -12.237564271179966\n",
      "evaluation reward: -11.599497097825886\n",
      "evaluation reward: -13.575363993489223\n",
      "evaluation reward: -12.956574908930822\n",
      "evaluation reward: -13.444811583200671\n",
      "evaluation reward: -28.340457806376204\n",
      "evaluation reward: -14.190900288678874\n",
      "evaluation reward: -13.135283477322755\n",
      "evaluation reward: -14.357400712894878\n",
      "evaluation reward: -12.080279873697634\n",
      "evaluation reward: -26.346575991910278\n",
      "evaluation reward: -14.265379373163697\n",
      "evaluation reward: -14.84867410238237\n",
      "evaluation reward: -14.051551458148843\n",
      "evaluation reward: -9.852980853207733\n",
      "evaluation reward: -14.1751088295105\n",
      "evaluation reward: -12.473906392348347\n",
      "evaluation reward: -15.73314264776619\n",
      "evaluation reward: -31.71166142903766\n",
      "evaluation reward: -11.996055393976494\n",
      "evaluation reward: -31.085800971966236\n",
      "evaluation reward: -26.22694893088865\n",
      "evaluation reward: -12.338700393896525\n",
      "evaluation reward: -13.91930477759486\n",
      "evaluation reward: -12.154302423952544\n",
      "evaluation reward: -12.577310822564026\n",
      "evaluation reward: -35.107349086398436\n",
      "evaluation reward: -13.405324025105454\n",
      "evaluation reward: -17.155780620198357\n",
      "evaluation reward: -21.708508422036527\n",
      "evaluation reward: -36.08524265081644\n",
      "evaluation reward: -26.27769244206741\n",
      "evaluation reward: -30.800209093945845\n",
      "evaluation reward: -18.51811374382531\n",
      "average reward: -17.133200524344662\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v3')\n",
    "env = NormalizeObservation(env)\n",
    "env = NormalizeReward(env)\n",
    "env = NumpyToTorch(env)\n",
    "\n",
    "evaluate(env, 100, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b6b0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
