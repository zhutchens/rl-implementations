{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861d4ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers.vector import NumpyToTorch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src.ppo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21511c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = 16\n",
    "env = gym.make_vec('HalfCheetah-v5', num_envs)\n",
    "env = NumpyToTorch(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3af7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-inf, inf, (16, 17), float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5cffa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.53934069e-01, -4.15187798e-01,  2.15971153e+00,\n",
       "         3.18977664e-01,  8.90886732e-01, -2.87816633e-01,\n",
       "        -8.90096057e-01,  3.57086495e-02, -4.00794141e-02,\n",
       "         3.73795318e-02, -5.98736088e-03, -3.38256399e-01,\n",
       "         8.46463941e-02, -2.71525219e-01, -2.32293166e-01,\n",
       "        -6.94653659e-01,  5.82397475e-03],\n",
       "       [-1.90681779e-01, -1.51327776e+00,  2.33368142e+00,\n",
       "         4.87526861e-01, -2.89424781e-03,  1.20935121e+00,\n",
       "         1.50221643e+00,  4.59030589e-01, -8.89572036e-01,\n",
       "        -6.99245821e-01, -3.49327805e+00, -1.75747424e+00,\n",
       "         9.34470834e-02,  1.01660605e-01, -1.31946997e+00,\n",
       "        -5.37342227e-01,  1.22197016e+00],\n",
       "       [ 3.20562220e+00,  1.32939551e+00, -3.35227089e-01,\n",
       "         5.28397099e-01,  1.31331035e+00,  5.41652722e-01,\n",
       "         3.35480773e-02,  2.06843330e-01, -2.45977546e-01,\n",
       "        -9.35136386e-01, -7.50002349e-01, -1.60611459e+00,\n",
       "         3.27039850e-01, -5.06690855e-01, -1.15816756e-02,\n",
       "         9.99201001e-01, -1.65960406e-01],\n",
       "       [ 4.92295166e-01,  1.59148391e+00, -1.28153235e-01,\n",
       "        -2.30156007e+00, -1.13103759e+00,  8.81411133e-01,\n",
       "        -6.58704437e-01, -1.38808263e+00,  1.71706003e-01,\n",
       "         1.06121211e+00, -1.41528550e+00, -9.94711665e-01,\n",
       "        -4.82369935e-01, -1.51062166e+00,  1.42067089e+00,\n",
       "         1.07150687e+00, -1.79209139e-02],\n",
       "       [ 6.95539401e-01,  5.71642190e-01, -2.95777531e-01,\n",
       "        -5.81890738e-01, -8.18121531e-01,  5.74453789e-01,\n",
       "        -2.09723597e-01, -6.05558689e-01, -6.25459329e-01,\n",
       "         9.90261508e-01,  1.02653828e-01,  5.06023888e-01,\n",
       "         1.13668375e+00,  9.71758990e-01, -1.29376841e-01,\n",
       "        -2.62806630e-01, -8.45768929e-01],\n",
       "       [-1.99337837e-01, -3.01430136e+00,  6.73848630e-01,\n",
       "        -7.34782228e-02, -9.68339285e-01,  1.61430083e+00,\n",
       "         1.50218538e+00, -2.07355631e+00,  3.12488583e-01,\n",
       "         1.38321164e+00,  4.15075176e-01, -1.06967980e-01,\n",
       "         2.53127107e+00,  7.07092970e-01,  1.45994929e-01,\n",
       "        -7.89353285e-01, -2.75186378e+00],\n",
       "       [-1.51873127e+00, -4.85365047e-02,  7.41226193e-01,\n",
       "         9.44701420e-01,  1.55012677e+00, -1.12317088e+00,\n",
       "        -7.39601603e-01, -9.22227799e-01, -5.74894456e-02,\n",
       "        -2.21176750e-01, -3.10132270e-01,  1.20170261e-01,\n",
       "         6.86938073e-01,  7.68648108e-01, -5.82650572e-01,\n",
       "         2.17170454e+00,  1.63822636e-01],\n",
       "       [ 3.60199528e-01, -7.81118996e-01,  6.22750401e-01,\n",
       "        -9.22786724e-01, -5.16297239e-01, -2.02121220e+00,\n",
       "         5.55807484e-02, -5.64187904e-01,  3.79014797e-01,\n",
       "         6.94112981e-01,  6.38058970e-01, -1.69852185e+00,\n",
       "         5.75476811e-01,  1.23885747e-01,  9.18584014e-01,\n",
       "        -4.05217976e-01,  2.18601404e-01],\n",
       "       [-3.63958241e-01,  6.11124631e-01,  1.28303525e+00,\n",
       "         5.75527693e-01,  1.24752259e+00, -1.50093480e+00,\n",
       "         3.75502016e-01, -1.22250394e+00,  3.04756172e-01,\n",
       "         3.29241896e-01,  9.15063985e-01, -6.85129454e-03,\n",
       "        -7.32550542e-01,  9.86292709e-01,  6.49180108e-01,\n",
       "         8.14228327e-01,  1.27449115e+00],\n",
       "       [-9.42307487e-01, -7.50437476e-01, -5.22889028e-01,\n",
       "         6.01137068e-01, -1.50564357e+00,  4.74759931e-02,\n",
       "        -1.55649485e+00, -5.73023201e-01,  3.70164658e-01,\n",
       "        -1.68090368e+00,  3.53573005e-01,  2.10857824e-01,\n",
       "         6.30000345e-01,  2.24798429e+00, -1.34096657e+00,\n",
       "        -1.17530501e-01,  2.03508549e+00],\n",
       "       [ 1.06655453e-01, -1.68653287e-01, -1.35868955e-01,\n",
       "         1.03493671e+00,  5.09136557e-01, -3.10311905e-01,\n",
       "        -3.22550244e-01, -2.45089033e-01,  1.31168272e+00,\n",
       "         7.54847871e-01,  3.82526076e-02,  6.37852988e-01,\n",
       "        -2.27233984e-02, -1.12620416e+00,  8.11592959e-01,\n",
       "         5.67720015e-02,  4.41477222e-01],\n",
       "       [ 1.64159524e-01, -9.56775506e-01, -2.24840166e-01,\n",
       "        -8.45338249e-01, -3.46657237e-01,  2.05238569e+00,\n",
       "        -7.98870834e-01,  1.28773057e+00, -4.16316919e-01,\n",
       "         1.67723913e-01,  1.45991154e+00, -2.67722080e-01,\n",
       "         6.70056982e-01,  7.12527067e-01,  1.15063509e-01,\n",
       "        -1.15102848e+00,  1.37952871e+00],\n",
       "       [ 3.63606019e-01, -9.81599509e-01, -1.54482038e+00,\n",
       "        -3.85096569e-01,  8.02555306e-01, -1.25113267e+00,\n",
       "        -1.28568921e-02, -1.29011383e+00, -1.61236159e+00,\n",
       "         9.08710432e-02, -1.77979313e+00,  2.14489500e-01,\n",
       "        -5.70161221e-01, -4.54152020e-01, -9.84703022e-01,\n",
       "         2.29810125e-01,  8.38972789e-01],\n",
       "       [-6.44218224e-01, -4.46633607e-01, -7.75127082e-01,\n",
       "        -6.35760236e-01,  1.54382093e+00, -1.40023886e+00,\n",
       "         6.59170499e-01,  9.94316178e-02,  2.11162961e-01,\n",
       "        -2.91529273e-01, -7.14899801e-01, -1.90644746e+00,\n",
       "         1.53833371e+00,  2.28831193e-01, -1.14165350e+00,\n",
       "        -6.83040414e-01,  1.12019789e+00],\n",
       "       [ 1.53125483e-01, -1.23486792e+00,  1.24359974e+00,\n",
       "         9.36361419e-01,  4.32005841e-01, -1.28607237e-01,\n",
       "        -5.87468317e-01, -6.60582763e-02,  1.17126758e+00,\n",
       "         1.68395216e+00,  1.25565383e+00, -2.26291512e-01,\n",
       "        -2.51089151e+00,  9.24994563e-02, -1.00035182e+00,\n",
       "         5.94307576e-01,  1.52855284e+00],\n",
       "       [-6.94310970e-02, -9.85358832e-01,  1.25221259e+00,\n",
       "         2.58547973e-01,  7.00510571e-01, -1.07934631e+00,\n",
       "         1.57107266e-01, -1.39231167e-01, -1.27528380e+00,\n",
       "         1.45403435e+00, -1.48669122e+00, -3.64676443e-01,\n",
       "        -6.44619010e-01, -1.49363405e+00, -8.99503901e-01,\n",
       "        -5.32206044e-01, -9.93311334e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34701438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d813d62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (16, 6), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb1114f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2640485 , -0.21387762,  0.31502616, -0.6683145 , -0.67426306,\n",
       "        -0.4037574 ],\n",
       "       [-0.85429204, -0.45009747, -0.24800266, -0.52005523, -0.0906904 ,\n",
       "         0.0472281 ],\n",
       "       [-0.7820101 , -0.7557616 , -0.3871553 , -0.7653157 , -0.2248515 ,\n",
       "         0.7055948 ],\n",
       "       [ 0.47772607,  0.22539389,  0.5294949 ,  0.4373729 ,  0.13195285,\n",
       "         0.69474113],\n",
       "       [ 0.6164335 , -0.17133895,  0.3093939 , -0.90942526, -0.4869076 ,\n",
       "         0.6116383 ],\n",
       "       [-0.16764264, -0.07907969, -0.2399339 ,  0.78842896,  0.00367948,\n",
       "        -0.8703105 ],\n",
       "       [ 0.9854848 , -0.29130217,  0.6343386 ,  0.7737198 , -0.13292608,\n",
       "        -0.29946578],\n",
       "       [ 0.81677693,  0.01175282,  0.47978106,  0.4260301 ,  0.21810643,\n",
       "        -0.4623843 ],\n",
       "       [-0.06986938,  0.64355445, -0.81893826, -0.16764517,  0.7568629 ,\n",
       "        -0.89384264],\n",
       "       [-0.654082  ,  0.05780401,  0.7828481 ,  0.40304184, -0.4847424 ,\n",
       "        -0.5013304 ],\n",
       "       [ 0.9014891 ,  0.69990426,  0.20517367,  0.29355642,  0.19900446,\n",
       "        -0.8560931 ],\n",
       "       [ 0.9380376 ,  0.5071043 , -0.40261206,  0.498789  , -0.93489724,\n",
       "         0.674254  ],\n",
       "       [-0.5517621 , -0.5186919 , -0.28485733,  0.20020369,  0.869605  ,\n",
       "         0.20771646],\n",
       "       [-0.73208463, -0.4644333 ,  0.38983518, -0.7686965 ,  0.9782236 ,\n",
       "        -0.43931025],\n",
       "       [-0.87568957, -0.950276  ,  0.6070531 , -0.14244655, -0.5952016 ,\n",
       "         0.48176417],\n",
       "       [ 0.7888728 ,  0.8312296 , -0.8519577 ,  0.2196384 , -0.15025762,\n",
       "         0.1651574 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f166bebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d699c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_state, _ = env.reset()\n",
    "sample_action = env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c83a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_state = sample_state.to(dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ac1176",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, reward, done, terminated, _ = env.step(sample_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9385ff17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3689, -0.2075, -0.3452, -0.2118,  0.5567,  0.1170,  0.2776, -0.0058,\n",
       "        -0.5314, -0.3450, -0.9260, -1.0288, -0.1353, -0.0359, -0.6564,  0.4207],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc54945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf675e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6333081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhutchens/projects/RL/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "in_features = 17\n",
    "out_features = env.action_space.shape[1]\n",
    "hidden_size = 256\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "actor = Actor(in_features, out_features, hidden_size, True).to(device)\n",
    "critic = Critic(in_features, 1, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5fd879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([16, 6]), scale: torch.Size([16, 6]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = actor.forward(sample_state.to(device))\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1f4c8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2908, -0.0482, -0.6239,  1.5232, -1.0395,  0.8230],\n",
       "        [ 1.5601, -0.9407,  1.1642, -0.9061,  1.5443,  2.1815],\n",
       "        [ 0.7084, -0.4770, -0.5627,  0.1744,  2.4641,  1.5010],\n",
       "        [ 0.5201,  1.2760, -1.6320,  0.7377, -1.4821, -0.7474],\n",
       "        [-1.1096, -0.3956,  0.9914, -0.1303,  0.2891,  0.5059],\n",
       "        [-0.3033, -0.1859,  1.2410,  1.7590,  1.3449,  0.7655],\n",
       "        [ 0.5111,  0.4649,  0.8023,  0.5425,  1.4005,  2.2546],\n",
       "        [ 1.0867, -0.3638,  0.5517, -2.6344, -2.3201, -1.6158],\n",
       "        [ 0.0598, -1.3480, -0.2545, -0.3957,  0.2394,  3.3644],\n",
       "        [ 0.6493,  0.8463, -0.1774,  0.3587, -0.9915,  0.9768],\n",
       "        [-0.6906, -0.2653, -0.5988, -0.7193,  0.9595,  1.2417],\n",
       "        [ 0.6123, -1.2001,  1.3169, -0.9664,  0.3326, -1.1760],\n",
       "        [-0.6160, -0.2433, -1.2729, -0.2269, -0.3267, -0.0141],\n",
       "        [ 0.0667, -0.9374,  0.3097,  1.8253, -0.0203,  0.4847],\n",
       "        [-0.7800, -1.3426, -0.9352, -1.7733, -0.2147, -0.2393],\n",
       "        [-0.1322, -1.0930,  0.3751, -1.6451, -0.0411, -0.2823]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = dist.sample()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "269548b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9459, -0.9191, -1.0798, -2.0587, -1.4179, -1.2809],\n",
       "        [-2.0428, -1.3020, -1.6739, -1.3357, -2.1714, -3.3712],\n",
       "        [-1.1280, -1.0017, -1.0412, -0.9319, -4.0684, -2.1004],\n",
       "        [-1.0234, -1.8241, -2.1461, -1.1839, -1.9583, -1.1730],\n",
       "        [-1.6085, -0.9743, -1.4791, -0.9304, -0.9749, -1.0637],\n",
       "        [-0.9853, -0.9257, -1.7694, -2.4472, -1.8862, -1.2383],\n",
       "        [-1.0193, -1.0632, -1.2969, -1.0594, -1.9565, -3.5329],\n",
       "        [-1.4434, -0.9621, -1.1060, -4.4161, -3.5057, -2.1683],\n",
       "        [-0.9189, -1.7306, -0.9375, -1.0029, -0.9598, -6.6987],\n",
       "        [-1.0949, -1.3353, -0.9255, -0.9798, -1.3742, -1.4285],\n",
       "        [-1.1995, -0.9387, -1.0615, -1.1854, -1.4226, -1.7308],\n",
       "        [-1.0707, -1.5540, -1.8744, -1.3961, -0.9880, -1.5806],\n",
       "        [-1.1472, -0.9340, -1.6409, -0.9475, -0.9586, -0.9191],\n",
       "        [-0.9190, -1.3007, -0.9883, -2.5671, -0.9191, -1.0529],\n",
       "        [-1.2708, -1.7252, -1.2958, -2.4963, -0.9344, -0.9401],\n",
       "        [-0.9383, -1.4464, -1.0181, -2.2856, -0.9189, -0.9483]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aca14a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3883, 0.3989, 0.3397, 0.1276, 0.2422, 0.2778],\n",
       "        [0.1297, 0.2720, 0.1875, 0.2630, 0.1140, 0.0343],\n",
       "        [0.3237, 0.3673, 0.3530, 0.3938, 0.0171, 0.1224],\n",
       "        [0.3594, 0.1614, 0.1169, 0.3061, 0.1411, 0.3094],\n",
       "        [0.2002, 0.3774, 0.2278, 0.3944, 0.3772, 0.3452],\n",
       "        [0.3733, 0.3962, 0.1704, 0.0865, 0.1516, 0.2899],\n",
       "        [0.3608, 0.3454, 0.2734, 0.3467, 0.1414, 0.0292],\n",
       "        [0.2361, 0.3821, 0.3309, 0.0121, 0.0300, 0.1144],\n",
       "        [0.3989, 0.1772, 0.3916, 0.3668, 0.3830, 0.0012],\n",
       "        [0.3346, 0.2631, 0.3963, 0.3754, 0.2530, 0.2397],\n",
       "        [0.3013, 0.3911, 0.3459, 0.3056, 0.2411, 0.1771],\n",
       "        [0.3428, 0.2114, 0.1534, 0.2476, 0.3723, 0.2058],\n",
       "        [0.3175, 0.3930, 0.1938, 0.3877, 0.3834, 0.3989],\n",
       "        [0.3989, 0.2723, 0.3722, 0.0768, 0.3989, 0.3489],\n",
       "        [0.2806, 0.1781, 0.2737, 0.0824, 0.3928, 0.3906],\n",
       "        [0.3913, 0.2354, 0.3613, 0.1017, 0.3989, 0.3874]],\n",
       "       grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.log_prob(sample).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002a1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0248],\n",
       "        [-0.0377],\n",
       "        [-0.0276],\n",
       "        [-0.0370],\n",
       "        [-0.0354],\n",
       "        [-0.0278],\n",
       "        [-0.0337],\n",
       "        [-0.0258],\n",
       "        [-0.0375],\n",
       "        [-0.0426],\n",
       "        [-0.0321],\n",
       "        [-0.0416],\n",
       "        [-0.0296],\n",
       "        [-0.0289],\n",
       "        [-0.0301],\n",
       "        [-0.0455]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic.forward(sample_state.to(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a39387a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.2\n",
    "gamma = 0.99\n",
    "lam = 0.95\n",
    "c1 = 0.5\n",
    "c2 = 0.01\n",
    "actor_lr = 0.0003\n",
    "critic_lr = 0.0003\n",
    "batch_size = 64\n",
    "\n",
    "agent = Agent(actor, critic, epsilon, gamma, lam, c1, c2, actor_lr, critic_lr, device, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0603f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished episode: 0\n",
      "total reward: -4922.101401027502\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 1\n",
      "total reward: -5027.751447337744\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 2\n",
      "total reward: -4962.422722528857\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 3\n",
      "total reward: -4533.981784855765\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 4\n",
      "total reward: -4442.382312998708\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 5\n",
      "total reward: -4533.637395424885\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 6\n",
      "total reward: -4172.444842753126\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 7\n",
      "total reward: -4424.0309468712485\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 8\n",
      "total reward: -3724.611578120898\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 9\n",
      "total reward: -3907.2666170924895\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 10\n",
      "total reward: -3802.5996372738346\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 11\n",
      "total reward: -4005.3954660809095\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 12\n",
      "total reward: -3521.6590115323675\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 13\n",
      "total reward: -3346.46987733355\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 14\n",
      "total reward: -3827.558335797475\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 15\n",
      "total reward: -3319.8469549979222\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 16\n",
      "total reward: -3615.615660506891\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 17\n",
      "total reward: -3611.553224852165\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 18\n",
      "total reward: -3105.7930239614084\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 19\n",
      "total reward: -3185.0941440653787\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 20\n",
      "total reward: -3135.922556679136\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 21\n",
      "total reward: -2792.414725666835\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 22\n",
      "total reward: -2780.3506717859664\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 23\n",
      "total reward: -2925.010168551915\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 24\n",
      "total reward: -2592.721343057302\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 25\n",
      "total reward: -2527.2524702717187\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 26\n",
      "total reward: -2303.8439367784704\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 27\n",
      "total reward: -1697.436432871206\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 28\n",
      "total reward: -2612.1128319819486\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 29\n",
      "total reward: -2243.130764995692\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 30\n",
      "total reward: -2144.952519722934\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 31\n",
      "total reward: -1563.6266341841815\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 32\n",
      "total reward: -1612.4061697643365\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 33\n",
      "total reward: -2116.2475405727037\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 34\n",
      "total reward: -1719.4549231905992\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 35\n",
      "total reward: -1760.7446719468442\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 36\n",
      "total reward: -1692.9602135767204\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 37\n",
      "total reward: -1158.560990114717\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 38\n",
      "total reward: -1306.9959336227862\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 39\n",
      "total reward: -1441.1842007736836\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 40\n",
      "total reward: -828.8630007176284\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 41\n",
      "total reward: -608.1176578598578\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 42\n",
      "total reward: -612.3893829128932\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 43\n",
      "total reward: -415.49147070515664\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 44\n",
      "total reward: -838.0077460516701\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 45\n",
      "total reward: -797.6645552683419\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 46\n",
      "total reward: -390.16155503283045\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 47\n",
      "total reward: 208.23490853122746\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 48\n",
      "total reward: -434.6346693737204\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 49\n",
      "total reward: -77.41961442285849\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 50\n",
      "total reward: 144.5587811142108\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 51\n",
      "total reward: 766.4530948767717\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 52\n",
      "total reward: 668.9867780443195\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 53\n",
      "total reward: 322.5612464097133\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 54\n",
      "total reward: 317.4777090892492\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 55\n",
      "total reward: 872.5781674058699\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 56\n",
      "total reward: 1202.4711988504312\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 57\n",
      "total reward: 1068.9805567298986\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 58\n",
      "total reward: 1929.0557302307711\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 59\n",
      "total reward: 1991.7279217975195\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 60\n",
      "total reward: 2181.8908384011975\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 61\n",
      "total reward: 1857.3197977510488\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 62\n",
      "total reward: 1994.7727936084582\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 63\n",
      "total reward: 2916.4707560607612\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 64\n",
      "total reward: 2406.902182549655\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 65\n",
      "total reward: 3086.2827886933246\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 66\n",
      "total reward: 2111.760349670367\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 67\n",
      "total reward: 3203.8970023031184\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 68\n",
      "total reward: 3691.0354876261167\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 69\n",
      "total reward: 3815.289900278419\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 70\n",
      "total reward: 3123.3993342493072\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 71\n",
      "total reward: 3020.6338680780113\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 72\n",
      "total reward: 3167.723158750313\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 73\n",
      "total reward: 4055.4969190294687\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 74\n",
      "total reward: 4193.909158941961\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 75\n",
      "total reward: 4724.420082152396\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 76\n",
      "total reward: 6069.946828788353\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 77\n",
      "total reward: 5083.676920168785\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 78\n",
      "total reward: 5275.813466352564\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 79\n",
      "total reward: 5706.6935982363075\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 80\n",
      "total reward: 6002.682495428818\n",
      "number of steps: 512\n",
      "---------------\n",
      "finished episode: 81\n",
      "total reward: 6533.991665848126\n",
      "number of steps: 512\n",
      "---------------\n",
      "new best model... saving...\n",
      "finished episode: 82\n",
      "total reward: 5956.630793576858\n",
      "number of steps: 512\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "train(env, agent, num_envs, 1000, 512, 4, 'models/halfcheetah.pt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1260bbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd3e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
